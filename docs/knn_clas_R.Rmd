---
title: "KNN para el análisis de variables cualitativas con R"
output: 
  pdf_document:
    number_sections: true
    toc: true
  html_document:
    number_sections: true
    toc: true
    toc_float: true
---

# Introducción

Se quiere predecir la especie de dos pingüinos con las siguientes características:

```{r echo=FALSE}
xp = data.frame(
  long_pico = c(39.8,46.1), 
  prof_pico = c(18.4,15.5),
  long_aleta = c(192,202), 
  peso = c(3250,4000),  
  isla = c("Dream","Biscoe"),
  genero = c("hembra","macho")
)
xp
```

utilizando los datos del archivo pinguinos.csv y el algoritmo KNN.

# Lectura y preparación de los datos

En primer lugar se leen los datos y se crean los factores correspondientes

```{r}
## se leen los datos
d = read.csv("datos/pinguinos.csv", sep = ";")
```

```{r}
# es conveniente convertir a factores las variables cualitativas
d$especie = factor(d$especie)
d$isla = factor(d$isla)
d$genero = factor(d$genero)
```

- Se normalizan los regresores numéricos:

```{r}
# se lee la funcion que normaliza
source("funciones/knn_funciones.R")
```

```{r}
# se normalizan y se guardan en un data.frame
d1 = data.frame(
  long_pico = knn_normaliza(d$long_pico),
  prof_pico = knn_normaliza(d$prof_pico),
  long_aleta = knn_normaliza(d$long_aleta),
  peso = knn_normaliza(d$peso)
)
```

- Se definen las variables auxiliares. En este caso se deciden utilizar una variable menos que el número de niveles:

```{r}
#
d1$isla_Bis = ifelse(d$isla == "Biscoe", 1, 0)
d1$isla_Dre = ifelse(d$isla == "Dream", 1, 0)
#
d1$genero_H = ifelse(d$genero == "hembra", 1, 0)
```

- Se preparan los valores que se quieren predecir:

```{r}
# variables cuantitativas normalizadas
xp1 = data.frame(
  long_pico = knn_normaliza(c(39.8,46.1), min(d$long_pico), max(d$long_pico)),
  prof_pico = knn_normaliza(c(18.4,15.5), min(d$prof_pico), max(d$prof_pico)),
  long_aleta = knn_normaliza(c(192,202), min(d$long_aleta), max(d$long_aleta)),
  peso = knn_normaliza(c(3250,4000), min(d$peso), max(d$peso))
)
# variables auxiliares
xp1$isla_Bis = c(0,1)
xp1$isla_Dre = c(1,0)
#
xp1$genero_H = c(1,0)
```

# Algoritmo KNN con R

Para aplicar el algoritmo se va a utilizar el paquete FNN de R:

```{r}
# se utiliza la funcion knn.reg del paquete FNN
yp = FNN::knn(d1, test = xp1, cl = d$especie, k = 3)
yp
```

- Se observa que se devuelve la predicción: Adelie, Gentoo
- attr(,"nn.index") devuelve los k puntos más cercanos.
- attr(,"nn.dist") devuelve la distancia de los k puntos más cercanos.

```{r}
# la especie de los k puntos más cercanos es
(p1 = attr(yp,"nn.index")[1,])
d$especie[p1]
```
Luego la predicción es Adelie.

## Cálculo del error de predicción: matriz de confusión

```{r}
# se crean los datos de entrenamiento y los datos test (80%-20%)
set.seed(678)
n = nrow(d)
pos_train = sample(1:n,round(0.8*n), replace = F)
train_x = d1[pos_train,]
test_x = d1[-pos_train,]
train_y = d$especie[pos_train]
test_y = d$especie[-pos_train]
```

```{r}
# se utiliza la funcion knn.reg del paquete FNN
yp = FNN::knn(train_x, test = test_x, cl = train_y, k = 1)
```

El método más sencillo para calcular el error de predicción es la **matriz de confusión**:

```{r}
# matriz de confusion
(t = table(test_y, yp))
```

Los valores de la diagonal de la matriz están bien predichos, los de fuera de la diagonal son errores de predicción:

```{r}
# error
1 - sum(diag(t))/sum(t)
```

Sólo hay dos pingüinos mal predichos, la predicción es prácticamente perfecta. Esto ocurre porque la longitud del pico y la profundidad del pico caracterizan muy bien la especie de los pingüinos:

```{r}
plot(d$long_pico, d$prof_pico, col = d$especie, pch = 19)
legend("bottomright", legend = c("Adelie","Chindstrap","Gentoo"), pch = 19, col = 1:3)
```

Si se observa el gráfico, todas las especies están agrupadas en  regiones muy bien delimitadas. Luego k = 1 es suficiente para realizar la predicción final:

```{r}
# se utilizan todos los datos
(yp = FNN::knn(d1, test = xp1, cl = d$especie, k = 1))
```

En caso contrario se podría calcular el k óptimo utilizando los subconjuntos train-test o validación cruzada.

## Cálculo de k con validación cruzada

Cuando se trata de un problema de clasicación se tiene que utilizar la función knn.cv:

```{r}
yp=FNN::knn.cv(train_x,train_y, k = 3)
str(yp)
```
El significado es el mismo que lo obtenido con *knn.reg*. La matriz de confusion nos da una medida del error de prediccion:

```{r}
(t = table(train_y,yp))
```

Por tanto, utilizando diferentes valores de k se obtiene:

```{r}
error = rep(0,20)
for (ii in 1:20){
  yp = FNN::knn.cv(train_x,train_y, k = ii)
  t = table(train_y,yp)
  error[ii] = 1 - sum(diag(t))/sum(t)
}
```

```{r}
plot(1:20,error, type = "b")
```

Se observa que el error siempre es pequeño, como máximo se clasifica mal una observación: error = 1/333 = 0.003
